{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvDA8AK7QOq-"
      },
      "source": [
        "# Configuración del entorno de Python\n",
        "\n",
        "Las siguiente celda corresponde a la instalación de las dependencias y librerias necesarias para el entrenamiento del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2gs-PL4xDkZ"
      },
      "source": [
        "# Configuración del entorno\n",
        "!apt-get -qq install xxd\n",
        "!pip install pandas numpy matplotlib\n",
        "!pip install tensorflow==2.0.0-rc1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* <code>!apt-get -qq install xxd:</code> Instala la herramienta xxd que se usa para convertir archivos binarios a formato hexadecimal.\n",
        "* <code>!pip install pandas numpy matplotlib:</code> Instala las bibliotecas pandas, numpy y matplotlib para el análisis de datos y la visualización.\n",
        "* <code>!pip install tensorflow==2.0.0-rc1:</code> Instala TensorFlow versión 2.0.0-rc1 para el desarrollo de la red nueronal."
      ],
      "metadata": {
        "id": "dOYBFuVaAuwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "coYmxj6QvuEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxk414PU3oy3"
      },
      "source": [
        "# Analizar y preparar los datos\n",
        "\n",
        "*   Esta sección lee los archivos CSV y los convierte a un formato adecuado para entrenar la red neuronal.\n",
        "*   Se normalizan los datos de entrada para que estén entre 0 y 1.\n",
        "* Se crea una matriz codificada \"one-hot\" para las salidas (gestos).\n",
        "\n",
        "Adicionalmente se dividen aleatoriamente los pares de entrada y salida para cada clase en conjuntos de datos:\n",
        "\n",
        "* 70 % para entrenamiento\n",
        "* 10 % para validación\n",
        "* 20 % para pruebas.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "# Fijamos las semillas para reproducibilidad\n",
        "SEED = 43\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "GESTURES = [\n",
        "    \"ayuda\",\n",
        "    \"comoestas\",\n",
        "    \"cuanto\",\n",
        "    \"donde\",\n",
        "    \"explicar\",\n",
        "    \"gracias\",\n",
        "    \"hola\",\n",
        "    \"perdon\",\n",
        "    \"porfavor\",\n",
        "    \"quepaso\"\n",
        "]\n",
        "\n",
        "SAMPLES_PER_GESTURE = 70\n",
        "NUM_GESTURES = len(GESTURES)\n",
        "ONE_HOT_ENCODED_GESTURES = np.eye(NUM_GESTURES)\n",
        "\n",
        "# Listas globales para train, val, test de TODAS las clases\n",
        "inputs_train = []\n",
        "outputs_train = []\n",
        "inputs_validation = []\n",
        "outputs_validation = []\n",
        "inputs_test = []\n",
        "outputs_test = []\n",
        "\n",
        "# Proporciones de split dentro de cada clase\n",
        "TRAIN_RATIO = 0.7\n",
        "VAL_RATIO = 0.1\n",
        "TEST_RATIO = 0.2\n",
        "\n",
        "for gesture_index in range(NUM_GESTURES):\n",
        "    gesture = GESTURES[gesture_index]\n",
        "\n",
        "    print(f\"Procesando la clase {gesture_index} -> '{gesture}'\")\n",
        "\n",
        "    # Leemos el CSV de la clase\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/Maestria/\" + gesture + \".csv\")\n",
        "\n",
        "    # Calculamos cuántas \"grabaciones\" hay\n",
        "    num_recordings = df.shape[0] // SAMPLES_PER_GESTURE\n",
        "    print(f\"\\tSe encontraron {num_recordings} grabaciones para la clase '{gesture}'.\")\n",
        "\n",
        "    # Codificación one-hot de la clase actual\n",
        "    output_class = ONE_HOT_ENCODED_GESTURES[gesture_index]\n",
        "\n",
        "    # Listas LOCALES para la clase actual (antes de hacer el split)\n",
        "    gesture_inputs = []\n",
        "    gesture_outputs = []\n",
        "\n",
        "    # Recolectamos todas las grabaciones para la clase\n",
        "    for i in range(num_recordings):\n",
        "        tensor = []\n",
        "        for j in range(SAMPLES_PER_GESTURE):\n",
        "            idx = i * SAMPLES_PER_GESTURE + j\n",
        "            tensor += [\n",
        "                (df['aX'][idx] + 4) / 8,\n",
        "                (df['aY'][idx] + 4) / 8,\n",
        "                (df['aZ'][idx] + 4) / 8,\n",
        "                (df['gX'][idx] + 2000) / 4000,\n",
        "                (df['gY'][idx] + 2000) / 4000,\n",
        "                (df['gZ'][idx] + 2000) / 4000,\n",
        "                df['Angle1'][idx] / 90,\n",
        "                df['Angle2'][idx] / 90,\n",
        "                df['Angle3'][idx] / 90,\n",
        "                df['Angle4'][idx] / 90,\n",
        "                df['Angle5'][idx] / 90\n",
        "            ]\n",
        "        gesture_inputs.append(tensor)\n",
        "        gesture_outputs.append(output_class)\n",
        "\n",
        "    # Convertimos a arrays (aunque para shuffle podemos usar listas)\n",
        "    gesture_inputs = np.array(gesture_inputs)\n",
        "    gesture_outputs = np.array(gesture_outputs)\n",
        "\n",
        "    # Mezclamos (aleatorizamos) SOLO dentro de la clase actual\n",
        "    combined = list(zip(gesture_inputs, gesture_outputs))\n",
        "    random.shuffle(combined)\n",
        "    gesture_inputs, gesture_outputs = zip(*combined)\n",
        "    gesture_inputs = np.array(gesture_inputs)\n",
        "    gesture_outputs = np.array(gesture_outputs)\n",
        "\n",
        "    # Hacemos el split en TRAIN, VAL, TEST (70/10/20)\n",
        "    total_gesture_samples = len(gesture_inputs)\n",
        "    train_size = int(TRAIN_RATIO * total_gesture_samples)\n",
        "    val_size = int(VAL_RATIO * total_gesture_samples)\n",
        "    # El resto para test\n",
        "    test_size = total_gesture_samples - train_size - val_size\n",
        "\n",
        "    # Divisiones para la clase actual\n",
        "    gesture_inputs_train = gesture_inputs[:train_size]\n",
        "    gesture_outputs_train = gesture_outputs[:train_size]\n",
        "\n",
        "    gesture_inputs_val = gesture_inputs[train_size:train_size + val_size]\n",
        "    gesture_outputs_val = gesture_outputs[train_size:train_size + val_size]\n",
        "\n",
        "    gesture_inputs_test = gesture_inputs[train_size + val_size:]\n",
        "    gesture_outputs_test = gesture_outputs[train_size + val_size:]\n",
        "\n",
        "    # Agregamos a las listas GLOBAL (para TODAS las clases)\n",
        "    inputs_train.extend(gesture_inputs_train)\n",
        "    outputs_train.extend(gesture_outputs_train)\n",
        "\n",
        "    inputs_validation.extend(gesture_inputs_val)\n",
        "    outputs_validation.extend(gesture_outputs_val)\n",
        "\n",
        "    inputs_test.extend(gesture_inputs_test)\n",
        "    outputs_test.extend(gesture_outputs_test)\n",
        "\n",
        "# Finalmente, convertimos a arrays de NumPy\n",
        "inputs_train = np.array(inputs_train)\n",
        "outputs_train = np.array(outputs_train)\n",
        "inputs_validation = np.array(inputs_validation)\n",
        "outputs_validation = np.array(outputs_validation)\n",
        "inputs_test = np.array(inputs_test)\n",
        "outputs_test = np.array(outputs_test)\n",
        "\n",
        "print(\"\\nCompletado el parsing y la preparación de TODOS los datos.\")\n",
        "print(\"Tamaño de inputs_train:\", inputs_train.shape)\n",
        "print(\"Tamaño de outputs_train:\", outputs_train.shape)\n",
        "print(\"Tamaño de inputs_validation:\", inputs_validation.shape)\n",
        "print(\"Tamaño de outputs_validation:\", outputs_validation.shape)\n",
        "print(\"Tamaño de inputs_test:\", inputs_test.shape)\n",
        "print(\"Tamaño de outputs_test:\", outputs_test.shape)"
      ],
      "metadata": {
        "id": "tNql1Fr1v1CH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSxUeYPNQbOg"
      },
      "source": [
        "# Entrenamiento de la Red Neuronal\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9g2n41p24nR"
      },
      "source": [
        "## Construir y entrenar el modelo\n",
        "\n",
        "* El modelo cuenta con tres capas densas.\n",
        "* Se compila el modelo con el optimizador 'rmsprop' y la función de pérdida 'categorical_crossentropy', teniendo como métrica de evaluación la precisión."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGNFa-lX24Qo"
      },
      "source": [
        "# Construir el modelo y entrenarlo\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(15, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(NUM_GESTURES, activation='softmax')) # Se utiliza softmax porque solo esperamos que ocurra un gesto por entrada\n",
        "\n",
        "model.compile(\n",
        "    optimizer='rmsprop',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "history = model.fit(inputs_train, outputs_train, epochs=30, batch_size=1, validation_data=(inputs_validate, outputs_validate))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUDPvaJE1wRE"
      },
      "source": [
        "## Etapa de verificación\n",
        "\n",
        "En esta sección se gráfica la pérdida del modelo durante el entrenamiento, para el conjunto de entrenamiento y el conjunto de validación:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxA0zCOaS35v"
      },
      "source": [
        "### Pérdida"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvFNHXoQzmcM"
      },
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
        "\n",
        "# Obtener la pérdida (loss) del entrenamiento y la validación desde el historial\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "# Graficar la pérdida del entrenamiento y la validación\n",
        "plt.plot(epochs, loss, 'g.', label='Pérdida de entrenamiento')\n",
        "plt.plot(epochs, val_loss, 'b', label='Pérdida de validación')\n",
        "plt.title('Pérdida de entrenamiento y validación')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guMjtfa42ahM"
      },
      "source": [
        "### Ejecución con datos de prueba\n",
        "Aqui se la prueba del modelo con los datos de prueba nunca antes vistos por el modelos, se inicia realizando las predicciones:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3Y0CCWJz2EK"
      },
      "source": [
        "# Usar el modelo para predecir las entradas de prueba\n",
        "predictions = model.predict(inputs_test)\n",
        "\n",
        "# Imprimir las predicciones y las salidas esperadas\n",
        "print(\"Predicciones =\\n\", np.round(predictions, decimals=3))\n",
        "print(\"Reales =\\n\", outputs_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Posteriormente se gráfica la matriz de confusión y el reporte de clasificación:"
      ],
      "metadata": {
        "id": "2wnqfLLA7QE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay,classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Obtener las predicciones y convertirlas a las clases predichas (argmax para clasificación)\n",
        "predicted_classes = np.argmax(predictions, axis=1)  # Convertir probabilidades a clases\n",
        "true_classes = np.argmax(outputs_test, axis=1)      # Convertir etiquetas one-hot a clases\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "# Mostrar la matriz de confusión\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
        "disp.plot(cmap='viridis')  # Puedes cambiar el colormap si lo deseas\n",
        "plt.title(\"Matriz de Confusión\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nReporte de clasificación:\\n\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "6cJbvgJk7UTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7DO6xxXVCym"
      },
      "source": [
        "# Convertir el modelo entrenado a TensorFlow Lite\n",
        "\n",
        "La siguiente celda convierte el modelo al formato TFlite. También se imprime el tamaño en bytes del modelo para asegurar que el tamaño funcione dentro del arduino."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xn1-Rn9Cp_8"
      },
      "source": [
        "# Convertir el modelo al formato TensorFlow Lite sin cuantización\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Guardar el modelo en disco\n",
        "open(\"gesture_model.tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "import os\n",
        "basic_model_size = os.path.getsize(\"gesture_model.tflite\")\n",
        "print(\"El modelo tiene un tamaño de %d bytes\" % basic_model_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykccQn7SXrUX"
      },
      "source": [
        "## Codificar el modelo en un archivo de encabezado de Arduino\n",
        "\n",
        "La siguiente celda crea una matriz de bytes constantes que contiene el modelo TFlite. Se importa el modelo para ser usado por Arduino:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J33uwpNtAku"
      },
      "source": [
        "!echo \"const unsigned char model[] = {\" > /content/model.h\n",
        "!cat gesture_model.tflite | xxd -i      >> /content/model.h\n",
        "!echo \"};\"                              >> /content/model.h\n",
        "\n",
        "import os\n",
        "model_h_size = os.path.getsize(\"model.h\")\n",
        "print(f\"El archivo de cabecera, model.h, tiene un tamaño de {model_h_size:,} bytes.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}